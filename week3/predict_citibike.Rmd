---
title: "Predict Citibike trips"
output: html_document
date: '2022-06-16'
---

```{r}
library(here)
library(scales)
library(tidyverse)
library(modelr)
library(lubridate)
library(broom)

theme_set(theme_bw())
options(repr.plot.width=4, repr.plot.height=3)

knitr::opts_chunk$set(echo = TRUE)
```


1. Trips per day file

```{r}

trips_per_day <- read_tsv('trips_per_day.tsv')

weather <- read_csv("weather.csv")

weather <- weather %>%
mutate(ymd = DATE)

trips_per_day <- inner_join(trips_per_day, weather, on = "ymd")

trips_per_day <- trips_per_day %>%
transmute(ymd, num_trips, prcp = PRCP, snwd = SNWD, snow = SNOW, tmax = TMAX, tmin = TMIN)

holiday <- read_csv('holidays.csv', col_names = FALSE)
colnames(holiday) = c("index", "ymd", "holiday")

holiday <- subset(holiday, select = -index)

trips_per_day <- left_join(trips_per_day, holiday, by = 'ymd') %>%
  mutate(is_holiday = !is.na(holiday)) %>%
  mutate(sub_rain = (prcp >= 0.5)) %>%
  mutate(day = wday(ymd), weekday = (day < 6))

View(trips_per_day)
```


2. Splitting the data into 10% for test and 90% for training & validation


```{r}

set.seed(42)
num_days <- nrow(trips_per_day)
frac_train_valid <- 0.9
num_train_valid <- floor(num_days * frac_train_valid)

#randomly sample rows for the training and validating
ndx <- sample(1:num_days, num_train_valid, replace=F)

# used to fit and evaluate the model
trips_per_day_train_valid <- trips_per_day[ndx, ]

# use later to test the model
trips_per_day_test <- trips_per_day[-ndx, ]


```

3. Training/Validate Set Plot

K-fold Cross-Validation

```{r}

set.seed(42)
num_folds <- 5
n_days <- nrow(trips_per_day_train_valid)
frac_k <- 0.8
train_k <- floor(n_days * frac_k)

samp <- sample(1:n_days, train_k, replace=F)

trips_days <- trips_per_day_train_valid[samp, ] %>%
  mutate(fold = (row_number() %% num_folds) + 1)


```


Fit a model for each polynomial degree

```{r}

K <- 1:8
avg_validate_err <- c()
se_validate_err <- c()
for (k in K) {
  valid_err <- c()
  for (f in 1:num_folds) {
    trips_train <- filter(trips_days, fold != f)
    model_k <- lm(num_trips ~ poly(tmin, k, raw = T), data = trips_train)
    
    trips_validate <- filter(trips_days, fold == f)
    valid_err[f] <- sqrt(mean((predict(model_k, trips_validate) - trips_validate$num_trips)^2))
  }
  
  avg_validate_err[k] <- mean(valid_err)
  se_validate_err[k] <- sd(valid_err) / sqrt(num_folds)
}

```


Plot the resulting average validation error as a function of polynomial degree

```{r}
plot_data_k <- data.frame(K, avg_validate_err, se_validate_err)

ggplot(plot_data_k, aes(x=K, y=avg_validate_err)) +
  geom_pointrange(aes(ymin=avg_validate_err - se_validate_err,
                       ymax = avg_validate_err + se_validate_err,
                       color = avg_validate_err == min(avg_validate_err))) +
  geom_line(color = 'red') +
  scale_x_continuous(breaks = 1:12) +
  theme(legend.position = 'none') +
  xlab('Polynomial Degree') +
  ylab('RMSE on validation data')

plot_data_k %>%
  summarize(minimum = min(avg_validate_err))

#RMSE = 5693.403
```

We see from the k-fold cross-validation that a fifth degree polynomial is a reasonable choice.


Plot the model:

```{r}
model1 <- lm(num_trips ~ poly(tmin, 5, raw = T), data = trips_train)

train <- trips_train %>%
  add_predictions(model1) %>%
  mutate(split = "train")
validate <- trips_validate %>%
  add_predictions(model1) %>%
  mutate(split = "validate")

plot_data <- bind_rows(train, validate)

ggplot(plot_data, aes(x = tmin, y = num_trips)) +
  geom_point(aes(color = split)) +
  geom_line(aes(y = pred)) + 
  xlab('Minimum temperature') +
  ylab('Daily trips') +
  scale_y_continuous()
```


4. Extend/improving the model


```{r}

K <- 1:8
avg_validate_err <- c()
se_validate_err <- c()
for (k in K) {
  valid_err <- c()
  for (f in 1:num_folds) {
    trips_train <- filter(trips_days, fold != f)
    model_new <- lm(num_trips ~ poly(tmin, k, raw = T) + sub_rain + prcp + snwd + snow + is_holiday + weekday + tmax, data = trips_train)
    
    trips_validate <- filter(trips_days, fold == f)
    valid_err[f] <- sqrt(mean((predict(model_new, trips_validate) - trips_validate$num_trips)^2))
  }
  
  avg_validate_err[k] <- mean(valid_err)
  se_validate_err[k] <- sd(valid_err) / sqrt(num_folds)
}

plot_data_new <- data.frame(K, avg_validate_err, se_validate_err)

plot_data_new %>%
  summarize(low = min(avg_validate_err))

plot_data_new %>%
  ggplot(aes(x=K, y=avg_validate_err)) +
  geom_pointrange(aes(ymin=avg_validate_err - se_validate_err,
                       ymax = avg_validate_err + se_validate_err,
                       color = avg_validate_err == min(avg_validate_err))) +
  geom_line(color = 'red') +
  scale_x_continuous(breaks = 1:12) +
  theme(legend.position = 'none') +
  xlab('Polynomial Degree') +
  ylab('RMSE on validation data')


```
The RMSE of 4241.836 is the lowest I've gotten after attempting multiple different arrangements of different variables.

```{r}

lmfit <- lm(num_trips ~ poly(tmin, 4, raw = T) + sub_rain + prcp + snow + snwd + weekday + is_holiday + tmax, data = trips_validate)

summary(lmfit)


```

Date vs Num_trips

```{r}

model_final <- lm(num_trips ~ poly(tmin, 4, raw = T) + sub_rain + prcp + snow + snwd + weekday + is_holiday + tmax, data = trips_train)

train_final <- trips_train %>%
  add_predictions(model_final) %>%
  mutate(split = "train")
validate_final <- trips_validate %>%
  add_predictions(model_final) %>%
  mutate(split = "validate")

plot_data_final <- bind_rows(train_final, validate_final)

ggplot(plot_data_final, aes(x = ymd, y = num_trips)) +
  geom_point(aes(color = split)) +
  geom_line(aes(y = pred)) + 
  xlab('Variables') +
  ylab('Daily trips') +
  scale_y_continuous()


ggplot(plot_data, aes(x = pred, y = num_trips)) +
  geom_point(aes(color = ymd)) + 
  geom_abline() + 
  xlab('Predicted Values') +
  ylab('Actual Values')

save(model_final, file = 'model_final.RData')

test_err <- sqrt(mean((predict(model_final, trips_per_day_test) - trips_per_day_test$num_trips)^2))

test_err

```


Test Set

```{r}

model_final <- lm(num_trips ~ poly(tmin, 4, raw = T) + sub_rain + prcp + snow + snwd + weekday + is_holiday + tmax, data = trips_per_day_test)
summary(model_final)

test_final <- trips_per_day_test %>%
  add_predictions(model_final)

ggplot(plot_data_final, aes(x = ymd, y = num_trips)) +
  geom_point() +
  geom_line(aes(y = pred)) + 
  xlab('Variables') +
  ylab('Daily trips') +
  scale_y_continuous()


```

The adjusted r-squared value here for the test set given the model that I created is 0.8943, which is pretty high. Although I'm not sure how my model would fit a different data set because there may be other factors during a different year that may impact the number of trips on a given day.



